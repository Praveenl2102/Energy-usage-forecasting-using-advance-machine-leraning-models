{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "df = pd.read_csv('C:\\IBM\\Tamilnadu power data.csv')\n",
    "df['Parameter'] = pd.to_datetime(df['Parameter'])\n",
    "df.columns = ['Date', 'Electricity']\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time-based features\n",
    "df['Month'] = df.index.month\n",
    "df['Year'] = df.index.year\n",
    "df['Day'] = df.index.day\n",
    "df['DayOfWeek'] = df.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create lag features\n",
    "def create_lag_features(data, lags):\n",
    "    for lag in lags:\n",
    "        data[f'lag_{lag}'] = data['Electricity'].shift(lag)\n",
    "    return data\n",
    "\n",
    "df = create_lag_features(df, [1, 7, 14, 30])\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Time Series Plot\n",
    "plt.plot(df.index, df['Electricity'])\n",
    "plt.title('Electricity Supply Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjusts the layout to ensure everything fits without overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='Electricity', by='Month')\n",
    "plt.title('Monthly Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Correlation Heatmap\n",
    "correlation = df[['Electricity', 'lag_1', 'lag_7', 'lag_14', 'lag_30']].corr()\n",
    "sns.heatmap(correlation, annot=True)\n",
    "plt.title('Correlation Heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. pie chart\n",
    "df['Month'] = df.index.month_name()  # Extract month names from the DateTime index\n",
    "\n",
    "# Group by the month and calculate the sum of 'Electricity' for each month\n",
    "monthly_consumption = df.groupby('Month')['Electricity'].sum()\n",
    "# Sort the months in calendar order\n",
    "monthly_consumption = monthly_consumption[['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                                           'July', 'August', 'September', 'October', 'November', 'December']]\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(monthly_consumption, labels=monthly_consumption.index, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired.colors)\n",
    "plt.title('Monthly Electricity Consumption Distribution')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Yearly Trend\n",
    "df.groupby('Year')['Electricity'].mean().plot(kind='bar')\n",
    "plt.title('Yearly Trend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Day of Week Pattern\n",
    "df.groupby('DayOfWeek')['Electricity'].mean().plot(kind='bar')\n",
    "plt.title('Day of Week Pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Lag Plot\n",
    "pd.plotting.lag_plot(df['Electricity'])\n",
    "plt.title('Lag Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Distribution Plot\n",
    "sns.histplot(df['Electricity'])\n",
    "plt.title('Distribution of Electricity Supply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Seasonal Decomposition Plot\n",
    "decomposition = seasonal_decompose(df['Electricity'], period=30)\n",
    "decomposition.plot()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Rolling Statistics\n",
    "df['Electricity'].rolling(window=30).mean().plot(label='30-day MA')\n",
    "df['Electricity'].rolling(window=7).mean().plot(label='7-day MA')\n",
    "plt.title('Rolling Statistics')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "def perform_kmeans_analysis(data, n_clusters=5):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    data['Cluster'] = kmeans.fit_predict(data[['Electricity']])\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n_clusters):\n",
    "        cluster_data = data[data['Cluster'] == i]\n",
    "        plt.scatter(cluster_data.index, cluster_data['Electricity'], label=f'Cluster {i}')\n",
    "    plt.title('K-Means Clustering of Electricity Supply')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model\n",
    "def fit_arima(data):\n",
    "    model = ARIMA(data['Electricity'], order=(1,1,1))\n",
    "    results = model.fit()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Smoothing\n",
    "def fit_exponential_smoothing(data):\n",
    "    model = ExponentialSmoothing(data['Electricity'], \n",
    "                                seasonal_periods=30,\n",
    "                                trend='add',\n",
    "                                seasonal='add')\n",
    "    results = model.fit()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Decomposition\n",
    "def perform_seasonal_decomposition(data):\n",
    "    decomposition = seasonal_decompose(data['Electricity'], period=30)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    decomposition.plot()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Neural Network\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = df[['Month', 'Year', 'Day', 'DayOfWeek', 'lag_1', 'lag_7', 'lag_14', 'lag_30']]\n",
    "y = df['Electricity'].values.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Label Encoding to 'Month' column\n",
    "label_encoder = LabelEncoder()\n",
    "X_train['Month'] = label_encoder.fit_transform(X_train['Month'])\n",
    "X_test['Month'] = label_encoder.transform(X_test['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store model performances\n",
    "model_performances = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(model, name, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "        # Define a threshold for accuracy (e.g., 10% of the true value)\n",
    "    threshold = 0.2\n",
    "    accuracy = np.mean(np.abs((y_test - y_pred) / y_test) < threshold) * 100\n",
    "    return {\n",
    "        'name': name,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'mae': mae,\n",
    "        'accuracy': accuracy,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. GLM (Linear Regression)\n",
    "lr_model = LinearRegression()\n",
    "model_performances['GLM'] = evaluate_model(lr_model, 'GLM', X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Neural Network\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000)\n",
    "model_performances['Neural Network'] = evaluate_model(nn_model, 'Neural Network', X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "model_performances['Gradient Boosting'] = evaluate_model(gb_model, 'Gradient Boosting', X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Decision Tree\n",
    "dt_model = DecisionTreeRegressor()\n",
    "model_performances['Decision Tree'] = evaluate_model(dt_model, 'Decision Tree', X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "model_performances['Random Forest'] = evaluate_model(rf_model, 'Random Forest', X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. SVM\n",
    "svm_model = SVR()\n",
    "model_performances['SVM'] = evaluate_model(svm_model, 'SVM', X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. k-NN\n",
    "knn_model = KNeighborsRegressor()\n",
    "model_performances['k-NN'] = evaluate_model(knn_model, 'k-NN', X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. AdaBoost (Boosting)\n",
    "ada_model = AdaBoostRegressor()\n",
    "model_performances['AdaBoost'] = evaluate_model(ada_model, 'AdaBoost', X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Stacking\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('gb', GradientBoostingRegressor()),\n",
    "    ('nn', MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000))\n",
    "]\n",
    "stack_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
    "model_performances['Stacking'] = evaluate_model(stack_model, 'Stacking', X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Time Series Models\n",
    "# ARIMA\n",
    "arima_model = fit_arima(df)\n",
    "arima_pred = arima_model.forecast(steps=len(y_test))\n",
    "# Calculate MAPE (Mean Absolute Percentage Error)\n",
    "mape = np.mean(np.abs((y_test - arima_pred) / y_test)) * 100\n",
    "model_performances['ARIMA'] = {\n",
    "    'name': 'ARIMA',\n",
    "    'rmse': np.sqrt(mean_squared_error(y_test, arima_pred)),\n",
    "    'r2': r2_score(y_test, arima_pred),\n",
    "    'mae': mean_absolute_error(y_test, arima_pred),\n",
    "    'accuracy': mape ,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Smoothing\n",
    "es_model = fit_exponential_smoothing(df)\n",
    "es_pred = es_model.forecast(len(y_test))\n",
    "mape = np.mean(np.abs((y_test - es_pred) / y_test)) * 100\n",
    "model_performances['Exponential Smoothing'] = {\n",
    "    'name': 'Exponential Smoothing',\n",
    "    'rmse': np.sqrt(mean_squared_error(y_test, es_pred)),\n",
    "    'r2': r2_score(y_test, es_pred),\n",
    "    'mae': mean_absolute_error(y_test, es_pred),\n",
    "    'accuracy': mape,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering Analysis\n",
    "kmeans_model = perform_kmeans_analysis(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Decomposition Analysis\n",
    "seasonal_decomp = perform_seasonal_decomposition(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.Series(y_train)\n",
    "print(type(y_train.values))\n",
    "print(y_train.values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Neural Network\n",
    "# Create graph structure\n",
    "def create_graph_structure(data):\n",
    "    # Create edges based on temporal relationships within training data\n",
    "    edge_index = []\n",
    "    for i in range(len(data) - 1):  # Ensure edges fit within data subset\n",
    "        edge_index.append([i, i + 1])\n",
    "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "# Create the edge_index for training data\n",
    "edge_index = create_graph_structure(X_train_scaled)\n",
    "# Filter edge_index to match training data size\n",
    "edge_index = edge_index[:, edge_index.max(dim=0).values < len(X_train_scaled)]\n",
    "\n",
    "x = torch.tensor(X_train_scaled, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_train.values, dtype=torch.float)\n",
    "\n",
    "gnn_model = GNNModel(X_train_scaled.shape[1], 64, 1)\n",
    "optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x shape: {x.shape}\")  # Should match the number of nodes\n",
    "print(f\"edge_index max: {edge_index.max().item()}\")  # Should be < len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GNN\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = gnn_model(x, edge_index)\n",
    "    loss = criterion(out.squeeze(), y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_structure_for_test(data_length):\n",
    "    # Create edges for test data only\n",
    "    edge_index = []\n",
    "    for i in range(data_length - 1):\n",
    "        edge_index.append([i, i + 1])\n",
    "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create edge_index for the test set\n",
    "test_edge_index = create_graph_structure_for_test(len(X_test_scaled))\n",
    "x_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    gnn_pred = gnn_model(x_test_tensor, test_edge_index).numpy()\n",
    "# Calculate MAPE (Mean Absolute Percentage Error)\n",
    "mape = np.mean(np.abs((y_test - gnn_pred) / y_test)) * 100\n",
    "\n",
    "# Calculate performance metrics\n",
    "model_performances['GNN'] = {\n",
    "    'name': 'GNN',\n",
    "    'rmse': np.sqrt(mean_squared_error(y_test, gnn_pred)),\n",
    "    'r2': r2_score(y_test, gnn_pred),\n",
    "    'mae': mean_absolute_error(y_test, gnn_pred),\n",
    "    'accuracy': mape,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model performances\n",
    "performance_df = pd.DataFrame(model_performances).T\n",
    "print(\"\\nModel Performances:\")\n",
    "print(performance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model\n",
    "best_model_name = performance_df['r2'].idxmax()\n",
    "print(f\"\\nBest Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future predictions using best model\n",
    "# Create future dates\n",
    "last_date = df.index[-1]\n",
    "future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=90, freq='D')\n",
    "\n",
    "# Create features for future dates\n",
    "future_df = pd.DataFrame(index=future_dates)\n",
    "future_df['Month'] = future_df.index.month\n",
    "future_df['Year'] = future_df.index.year\n",
    "future_df['Day'] = future_df.index.day\n",
    "future_df['DayOfWeek'] = future_df.index.dayofweek\n",
    "\n",
    "# Use last known values for lag features\n",
    "future_df['lag_1'] = df['Electricity'].iloc[-1]\n",
    "future_df['lag_7'] = df['Electricity'].iloc[-7]\n",
    "future_df['lag_14'] = df['Electricity'].iloc[-14]\n",
    "future_df['lag_30'] = df['Electricity'].iloc[-30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale future features\n",
    "future_features_scaled = scaler.transform(future_df)\n",
    "\n",
    "# Make predictions using the Gradient Boosting model\n",
    "if best_model_name == 'Gradient Boosting':\n",
    "    future_predictions = gb_model.predict(future_features_scaled)  # Using the Gradient Boosting model for prediction\n",
    "\n",
    "# Create predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=future_dates, data={'Predicted_Electricity': future_predictions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df.index, df['Electricity'], label='Historical Data')\n",
    "plt.plot(predictions_df.index, predictions_df['Predicted_Electricity'], label='Predictions')\n",
    "plt.title('Electricity Supply: Historical Data and Predictions')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024 = df[df.index.year == 2024]\n",
    "# Visualize historical data for 2024 and predictions for the next 3 months\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df_2024.index, df_2024['Electricity'], label='Historical Data (2024)')\n",
    "\n",
    "# Plot predictions for the next 3 months\n",
    "plt.plot(predictions_df.index, predictions_df['Predicted_Electricity'], label='Predictions (Next 3 Months)', linestyle='--')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Electricity Supply: Historical Data (2024) and Predictions for Next 3 Months')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout for better visualization\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPredictions for next 3 months:\")\n",
    "print(predictions_df.head(90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('electricity_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
